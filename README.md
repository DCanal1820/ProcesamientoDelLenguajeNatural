# Procesamiento de Lenguaje Natural I - Desafios

<img src="https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg" width="300" align="center">

## Universidad de Buenos Aires (UBA) - Facultad de Ingenier√≠a (FIUBA)
### Laboratorio de Sistemas Embebidos
### Carrera de Especializaci√≥n en Ingenier√≠a Artificial (CEIA)
### Materia: Procesamiento del Lenguaje Natural

**Estudiante:** Mg. Ing. David Canal  

---

## üìã Descripci√≥n General

Este repositorio contiene la implementaci√≥n de cuatro desafIos pr√°cticos realizados en el marco de la materia Procesamiento de Lenguaje Natural I de la CEIA de la FIUBA. Cada desafio aborda diferentes aspectos fundamentales del procesamiento de lenguaje natural, desde t√©cnicas b√°sicas de vectorizaci√≥n hasta modelos avanzados de redes neuronales recurrentes.

Los desafios fueron desarrollados utilizando Python y diversas librer√≠as especializadas en NLP, incluyendo scikit-learn, TensorFlow/Keras, PyTorch, Gensim y otras herramientas modernas del ecosistema de machine learning.

---

## üéØ Desafios Implementados

### üìä Desafio 1: Vectorizaci√≥n y Clasificaci√≥n de Documentos
**Archivo:** `Desafio 1/Canal_Desafio_1.ipynb`

#### Objetivos
- Implementar t√©cnicas de vectorizaci√≥n de documentos usando TF-IDF
- Analizar similitudes entre documentos mediante similaridad coseno
- Desarrollar modelos de clasificaci√≥n por prototipos (zero-shot)
- Optimizar modelos Na√Øve Bayes para clasificaci√≥n de texto
- Explorar similitudes entre palabras mediante matrices transpuestas

#### T√©cnicas Implementadas
- **Vectorizaci√≥n TF-IDF** con scikit-learn
- **Similaridad coseno** para an√°lisis de documentos
- **Clasificaci√≥n por prototipos** (modelo zero-shot)
- **Na√Øve Bayes** (MultinomialNB y ComplementNB) con optimizaci√≥n de hiperpar√°metros
- **An√°lisis de similitud entre palabras** usando matrices t√©rmino-documento

#### Dataset
- **20newsgroups**: 11,314 documentos de entrenamiento y 7,532 de test
- **20 categor√≠as** tem√°ticas diferentes

#### Resultados Destacados
- **Coherencia promedio**: 68% en an√°lisis de similitud de documentos
- **Mejor modelo**: ComplementNB con bigramas (F1-macro: 0.7015)
- **An√°lisis sem√°ntico**: Identificaci√≥n exitosa de relaciones entre palabras

---

### üî§ Desafio 2: Word Embeddings con Word2Vec
**Archivo:** `Desafio 2/Desafio_2_Canal_David.ipynb`

#### Objetivos
- Crear embeddings personalizados usando Word2Vec (Skip-gram)
- Analizar similitudes sem√°nticas entre palabras
- Implementar visualizaciones 2D y 3D con t-SNE
- Realizar clustering con K-means para identificar grupos sem√°nticos

#### T√©cnicas Implementadas
- **Word2Vec Skip-gram** con Gensim
- **Preprocesamiento** con Keras text_to_word_sequence
- **Visualizaci√≥n** con t-SNE (2D y 3D)
- **Clustering K-means** con an√°lisis de Silhouette Score
- **An√°lisis sem√°ntico** de palabras relacionadas

#### Dataset
- **Canciones de Britney Spears**: 3,848 l√≠neas de letras
- **Vocabulario**: 620 palabras √∫nicas
- **Vectores**: 300 dimensiones

#### Resultados Destacados
- **Vocabulario entrenado**: 620 palabras
- **Convergencia**: P√©rdida reducida de 197,458 a 79,613
- **Clustering √≥ptimo**: k=2 clusters con Silhouette Score de 0.0865
- **Temas identificados**: Amor, empoderamiento femenino, m√∫sica, baile

---

### üß† Desafio 3: Modelo de Lenguaje con RNN
**Archivo:** `Desafio 3/Desafio_3_Canal_David.ipynb`

#### Objetivos
- Implementar modelos de lenguaje usando redes neuronales recurrentes
- Comparar arquitecturas: SimpleRNN, LSTM y GRU
- Desarrollar estrategias de generaci√≥n de texto (Greedy, Beam Search)
- Crear interfaz interactiva con Gradio

#### T√©cnicas Implementadas
- **Tokenizaci√≥n por caracteres** (vocabulario de 42 caracteres)
- **Arquitecturas RNN**: SimpleRNN, LSTM, GRU
- **Estructura Many-to-Many** para aprendizaje denso
- **Callback personalizado** con m√©trica de perplejidad
- **Estrategias de generaci√≥n**:
  - Greedy Search
  - Beam Search Determin√≠stico
  - Beam Search Estoc√°stico con temperatura
- **Interfaz interactiva** con Gradio

#### Dataset
- **El Quijote** de Miguel de Cervantes
- **100,000 caracteres** procesados
- **Vocabulario**: 42 caracteres √∫nicos

#### Resultados Destacados
- **Mejor modelo**: GRU (perplejidad: 4.7408)
- **Eficiencia**: GRU m√°s eficiente que LSTM
- **Convergencia**: Mejora del 42.58% en perplejidad
- **Generaci√≥n**: Texto coherente con estilo cervantino

---

### ü§ñ Desafio 4: QA Bot con LSTM
**Archivo:** `Desafio 4/Desafio_4_Canal_David.ipynb`

#### Objetivos
- Construir un chatbot de preguntas y respuestas usando arquitectura Seq2Seq
- Implementar encoder-decoder con LSTM
- Utilizar embeddings FastText espa√±oles
- Evaluar el desempe√±o con preguntas espec√≠ficas

#### T√©cnicas Implementadas
- **Arquitectura Seq2Seq** con encoder-decoder
- **LSTM** con dropout (0.2) y 128 unidades
- **Embeddings FastText** espa√±oles (300 dimensiones)
- **Tokenizaci√≥n** con tokens especiales (<sos>, <eos>)
- **Entrenamiento** con early stopping
- **Funci√≥n de generaci√≥n** simplificada pero funcional

#### Configuraci√≥n T√©cnica
- **MAX_VOCAB_SIZE**: 8,000
- **MAX_INPUT_LEN**: 16 caracteres
- **MAX_OUT_LEN**: 18 caracteres
- **EMBEDDING_DIM**: 300 (FastText espa√±ol)
- **LSTM_UNITS**: 128
- **DROPOUT**: 0.2
- **EPOCHS**: 40 (dentro del rango 30-50)

#### Dataset
- **8,000 pares QA** expandidos con variaciones
- **Preguntas sugeridas** incluidas:
  - "Do you read?"
  - "Do you have any pet?"
  - "Where are you from?"

#### Resultados Destacados
- **Accuracy final**: 100% en entrenamiento y validaci√≥n
- **Loss final**: 0.019 (entrenamiento), 0.018 (validaci√≥n)
- **Respuestas coherentes** para todas las preguntas de prueba
- **Modelo funcional** con 571,540 par√°metros

---

## üõ†Ô∏è Tecnolog√≠as Utilizadas

### Librer√≠as Principales
- **scikit-learn**: Vectorizaci√≥n, clasificaci√≥n, m√©tricas
- **TensorFlow/Keras**: Redes neuronales recurrentes
- **PyTorch**: Implementaci√≥n del QA Bot
- **Gensim**: Word2Vec y embeddings
- **NumPy/Pandas**: Manipulaci√≥n de datos
- **Matplotlib/Seaborn**: Visualizaciones
- **Gradio**: Interfaz interactiva

### Herramientas de Procesamiento
- **NLTK/spaCy**: Preprocesamiento de texto
- **BeautifulSoup**: Parsing de HTML
- **scikit-learn**: Tokenizaci√≥n y padding
- **t-SNE**: Reducci√≥n dimensional
- **K-means**: Clustering

---

## üìà M√©tricas y Resultados

### Desafio 1: Clasificaci√≥n
- **F1-Score macro**: 0.7015 (ComplementNB con bigramas)
- **Coherencia similitud**: 68% promedio
- **Accuracy**: 48.6% (modelo prototipos)

### Desafio 2: Word Embeddings
- **Vocabulario**: 620 palabras
- **Convergencia**: 20 √©pocas
- **Silhouette Score**: 0.0865 (k=2)

### Desafio 3: Modelo de Lenguaje
- **Perplejidad**: 4.7408 (GRU)
- **Accuracy**: 51.01% (GRU)
- **Tiempo entrenamiento**: 1,141 segundos

### Desafio 4: QA Bot
- **Accuracy**: 100% (entrenamiento y validaci√≥n)
- **Loss**: 0.018 (validaci√≥n)
- **Par√°metros**: 571,540

---

## üéì Aprendizajes y Conclusiones

### T√©cnicas Fundamentales
1. **Vectorizaci√≥n**: TF-IDF como base s√≥lida para representaci√≥n de documentos
2. **Embeddings**: Word2Vec para capturar relaciones sem√°nticas
3. **RNN**: LSTM y GRU para modelado de secuencias
4. **Seq2Seq**: Arquitectura encoder-decoder para tareas conversacionales

### Insights T√©cnicos
- **ComplementNB** supera a MultinomialNB en datasets desbalanceados
- **GRU** ofrece mejor balance eficiencia-rendimiento que LSTM
- **Tokenizaci√≥n por caracteres** permite mayor flexibilidad
- **Beam Search** mejora la calidad de generaci√≥n vs Greedy Search

### Aplicaciones Pr√°cticas
- **Sistemas de recomendaci√≥n** basados en contenido
- **An√°lisis de sentimientos** y clasificaci√≥n de texto
- **Generaci√≥n autom√°tica** de contenido
- **Chatbots conversacionales** para atenci√≥n al cliente

---

## üìÅ Estructura del Repositorio

```
Desafios_Canal/
‚îú‚îÄ‚îÄ README.md                           # Este archivo
‚îú‚îÄ‚îÄ Desafio 1/
‚îÇ   ‚îî‚îÄ‚îÄ Canal_Desafio_1.ipynb          # Vectorizaci√≥n y clasificaci√≥n
‚îú‚îÄ‚îÄ Desafio 2/
‚îÇ   ‚îî‚îÄ‚îÄ Desafio_2_Canal_David.ipynb    # Word embeddings
‚îú‚îÄ‚îÄ Desafio 3/
‚îÇ   ‚îî‚îÄ‚îÄ Desafio_3_Canal_David.ipynb    # Modelo de lenguaje RNN
‚îî‚îÄ‚îÄ Desafio 4/
    ‚îú‚îÄ‚îÄ Desafio_4_Canal_David.ipynb    # QA Bot
    ‚îú‚îÄ‚îÄ qa_bot_canal_david.csv          # Evaluaci√≥n del bot
    ‚îî‚îÄ‚îÄ torch_helpers.py                # Utilidades PyTorch
```

---

## üöÄ C√≥mo Ejecutar los desafios

### Requisitos Previos
```bash
pip install numpy pandas matplotlib seaborn
pip install scikit-learn tensorflow torch
pip install gensim nltk gradio
pip install beautifulsoup4 requests
```

### Ejecuci√≥n
1. **desafio 1**: Abrir `Canal_Desafio_1.ipynb` y ejecutar todas las celdas
2. **desafio 2**: Abrir `Desafio_2_Canal_David.ipynb` y ejecutar secuencialmente
3. **desafio 3**: Abrir `Desafio_3_Canal_David.ipynb` y ejecutar (incluye interfaz Gradio)
4. **desafio 4**: Abrir `Desafio_4_Canal_David.ipynb` y ejecutar para entrenar el QA Bot

---

## üìö Referencias y Material de Clase

Este trabajo se realiz√≥ utilizando el material de clases y ejercicios proporcionados en el repositorio oficial de la materia:

**Contenido del Curso:**
- Clase 1: Introducci√≥n a NLP y vectorizaci√≥n de documentos
- Clase 2: Preprocesamiento de texto e information-retrieval bots
- Clase 3: Word embeddings, CBOW y SkipGRAM
- Clase 4: Redes recurrentes (RNN) y problemas de secuencia
- Clase 5: Redes LSTM y an√°lisis de sentimiento
- Clase 6: Modelos Seq2Seq, bots conversacionales y traductores
- Clase 7: Celdas con Attention, Transformers, BERT y ELMo
- Clase 8: Deployment de servicios NLP, Flask, APIs, Docker y Tensorflow Serving
