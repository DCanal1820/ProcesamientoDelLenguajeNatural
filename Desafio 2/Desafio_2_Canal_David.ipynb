{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXqu2BjoZlcW"
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "# **Procesamiento del Lenguaje Natural - Desafío 2**\n",
    "---\n",
    "##*Facultad de Ingeniería de la Universidad de Buenos Aires*\n",
    "##*Laboratorio de Sistemas Embebidos*                                  \n",
    "##*David Canal*\n",
    "---\n",
    "##**Consigna de trabajo**\n",
    "---\n",
    "* Crear sus propios vectores con Gensim basado en lo visto en clase con otro dataset.\n",
    "\n",
    "* Probar términos de interés y explicar similitudes en el espacio de embeddings (sacar conclusiones entre palabras similitudes y diferencias).\n",
    "\n",
    "* Graficarlos.\n",
    "\n",
    "* Obtener conclusiones.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWdiG_aJZlca"
   },
   "source": [
    "##**Resolución**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18487,
     "status": "ok",
     "timestamp": 1760825886243,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "GV8MN0faZlca",
    "outputId": "0562030d-4d07-4832-9ceb-4f4b1632f4f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/anaconda3/lib/python3.13/site-packages (4.4.0)\n",
      "Requirement already satisfied: tensorflow in /opt/anaconda3/lib/python3.13/site-packages (2.20.0)\n",
      "Requirement already satisfied: seaborn in /opt/anaconda3/lib/python3.13/site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in /opt/anaconda3/lib/python3.13/site-packages (5.24.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /opt/anaconda3/lib/python3.13/site-packages (from gensim) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from gensim) (1.15.3)\n",
      "Requirement already satisfied: smart_open>=1.8.1 in /opt/anaconda3/lib/python3.13/site-packages (from gensim) (7.3.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.3.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (5.29.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (72.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.17.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (1.75.1)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.11.3)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (3.12.1)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in /opt/anaconda3/lib/python3.13/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.8)\n",
      "Requirement already satisfied: pillow in /opt/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (11.1.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.13/site-packages (from seaborn) (2.2.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /opt/anaconda3/lib/python3.13/site-packages (from seaborn) (3.10.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from plotly) (9.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (13.9.4)\n",
      "Requirement already satisfied: namex in /opt/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: optree in /opt/anaconda3/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/lib/python3.13/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/anaconda3/lib/python3.13/site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim tensorflow seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 5688,
     "status": "ok",
     "timestamp": 1760825891946,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "tm3iakrAZlcc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import multiprocessing\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "44_BlQv1Zlcc"
   },
   "source": [
    "## 1. Selección y preparación del dataset\n",
    "\n",
    "### **Dataset elegido: Britney Spears**\n",
    "\n",
    "Se seleccionó el dataset de Britney Spears por las siguientes razones (además de que soy fan de la artista):\n",
    "\n",
    "- Riqueza semántica: las canciones pop contienen vocabulario emocional y conceptual diverso.\n",
    "- Consistencia de estilo: un solo artista permite analizar patrones semánticos específicos.\n",
    "- Temática característica: Palabras relacionadas con amor, baile, música, entre otros.\n",
    "- Volumen adecuado: Suficiente texto para entrenar embeddings de calidad.\n",
    "\n",
    "### **Descarga y preparación del dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1760825892759,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "a2edIYbfZlcc",
    "outputId": "71ec7de7-f0c5-40eb-f511-50416491bf0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset ya se encuentra descargado\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import platform\n",
    "if os.access('./songs_dataset', os.F_OK) is False:\n",
    "    if os.access('songs_dataset.zip', os.F_OK) is False:\n",
    "        if platform.system() == 'Windows':\n",
    "            !curl https://raw.githubusercontent.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/main/datasets/songs_dataset.zip -o songs_dataset.zip\n",
    "        else:\n",
    "            !wget songs_dataset.zip https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/datasets/songs_dataset.zip\n",
    "    !unzip -q songs_dataset.zip\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1760825892782,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "qHUQ-1JfZlcc",
    "outputId": "21342aba-0e65-4a70-849e-9f613621ca37"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['prince.txt',\n",
       " 'dickinson.txt',\n",
       " 'notorious-big.txt',\n",
       " 'beatles.txt',\n",
       " 'bob-dylan.txt',\n",
       " 'bjork.txt',\n",
       " 'johnny-cash.txt',\n",
       " 'disney.txt',\n",
       " 'janisjoplin.txt',\n",
       " 'kanye.txt',\n",
       " 'bob-marley.txt',\n",
       " 'leonard-cohen.txt',\n",
       " 'ludacris.txt',\n",
       " 'adele.txt',\n",
       " 'alicia-keys.txt',\n",
       " 'joni-mitchell.txt',\n",
       " 'amy-winehouse.txt',\n",
       " 'lorde.txt',\n",
       " 'rihanna.txt',\n",
       " 'Kanye_West.txt',\n",
       " 'nirvana.txt',\n",
       " 'cake.txt',\n",
       " 'bieber.txt',\n",
       " 'notorious_big.txt',\n",
       " 'missy-elliott.txt',\n",
       " 'dolly-parton.txt',\n",
       " 'jimi-hendrix.txt',\n",
       " 'michael-jackson.txt',\n",
       " 'al-green.txt',\n",
       " 'lil-wayne.txt',\n",
       " 'lady-gaga.txt',\n",
       " 'lin-manuel-miranda.txt',\n",
       " 'nursery_rhymes.txt',\n",
       " 'dj-khaled.txt',\n",
       " 'radiohead.txt',\n",
       " 'patti-smith.txt',\n",
       " 'blink-182.txt',\n",
       " 'Lil_Wayne.txt',\n",
       " 'dr-seuss.txt',\n",
       " 'r-kelly.txt',\n",
       " 'drake.txt',\n",
       " 'britney-spears.txt',\n",
       " 'bruce-springsteen.txt',\n",
       " 'nicki-minaj.txt',\n",
       " 'kanye-west.txt',\n",
       " 'paul-simon.txt',\n",
       " 'nickelback.txt',\n",
       " 'eminem.txt',\n",
       " 'bruno-mars.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar bandas disponibles\n",
    "os.listdir(\"./songs_dataset/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6By_g9TPZlcd"
   },
   "source": [
    "### **Carga del dataset de Britney Spears**\n",
    "\n",
    "Se carga el archivo con la canción de Britney Spears, utilizando saltos de línea para separar las oraciones. Esto permite que cada línea de la canción sea tratada como un documento independiente para el entrenamiento de Word2Vec.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 262
    },
    "executionInfo": {
     "elapsed": 88,
     "status": "ok",
     "timestamp": 1760825892871,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "K7coJ52_Zlcd",
    "outputId": "cc71d50f-5793-45fc-b58f-01275fa6fd5f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/k9/pf55qdhj1jz8kc2j3csc8c4h0000gn/T/ipykernel_66851/2544343471.py:2: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  df = pd.read_csv('songs_dataset/britney-spears.txt', sep='/n', header=None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>They say get ready for the revolution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I think it's time we find some sorta solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Somebody's caught up in the endless pollution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They need to wake up, stop living illusions I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Why won't somebody feel this</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0              They say get ready for the revolution\n",
       "1      I think it's time we find some sorta solution\n",
       "2      Somebody's caught up in the endless pollution\n",
       "3  They need to wake up, stop living illusions I ...\n",
       "4                       Why won't somebody feel this"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Armar el dataset utilizando salto de línea para separar las oraciones/docs\n",
    "df = pd.read_csv('songs_dataset/britney-spears.txt', sep='/n', header=None)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLMDTKwMZlcd"
   },
   "source": [
    "### **Estadísticas del dataset**\n",
    "\n",
    "El dataset de Britney Spears contiene **3,848 documentos** (líneas de canciones), lo que proporciona un corpus suficiente para entrenar embeddings de calidad. Cada documento representa una línea de letra de canción que será procesada individualmente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1760825892896,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "wEU8s_FIZlcd",
    "outputId": "33fbea36-2bdc-4843-98bc-240a998d228f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de documentos: 3848\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de documentos:\", df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIMiFQEDZlcd"
   },
   "source": [
    "## 2. Preprocesamiento\n",
    "\n",
    "### **Tokenización del texto**\n",
    "\n",
    "Con el fin de preprocesar este dataset para ser usado con Word2Vec, el cual trabaja con palabras limpias y normalizadas, se utilizó `text_to_word_sequence` de Keras para convertir cada línea de canción en una secuencia de palabras. Este método permitió:\n",
    "- Conviertir el texto a minúsculas.\n",
    "- Eliminar la puntuación.\n",
    "- Dividir en tokens individuales.\n",
    "- Filtrar caracteres especiales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6583,
     "status": "ok",
     "timestamp": 1760825899503,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "rVHx513JZlce"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import text_to_word_sequence\n",
    "\n",
    "sentence_tokens = []\n",
    "# Recorrer todas las filas y transformar las oraciones\n",
    "# en una secuencia de palabras (esto podría realizarse con NLTK o spaCy también)\n",
    "for _, row in df[:None].iterrows():\n",
    "    sentence_tokens.append(text_to_word_sequence(row[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RrMytOMQZlce"
   },
   "source": [
    "### **Resultado del preprocesamiento**\n",
    "\n",
    "A continuación se muestran los primeros dos documentos tokenizados para verificar que el preprocesamiento se realizó correctamente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1760825899515,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "Zb-UKm_AZlce",
    "outputId": "47cfaa2b-4992-4c1b-d578-e9124162b412"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['they', 'say', 'get', 'ready', 'for', 'the', 'revolution'],\n",
       " ['i', 'think', \"it's\", 'time', 'we', 'find', 'some', 'sorta', 'solution']]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demos un vistazo\n",
    "sentence_tokens[:2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DDtUODukZlce"
   },
   "source": [
    "## 3. Crear los vectores (word2vec)\n",
    "\n",
    "### **Configuración del modelo Word2Vec**\n",
    "\n",
    "Se utilizó el modelo **Skip-gram** de Word2Vec con los siguientes parámetros:\n",
    "- min_count=5: solo incluye palabras que aparecen al menos 5 veces.\n",
    "- window=2: considera 2 palabras antes y después del contexto.\n",
    "- vector_size=300: vectores de 300 dimensiones.\n",
    "- negative=20: 20 muestras negativas para entrenamiento.\n",
    "- sg=1: una Skip-gram (1) en lugar de CBOW (0).\n",
    "\n",
    "### **Callback para monitoreo del entrenamiento**\n",
    "\n",
    "Se implementa un callback personalizado para mostrar la pérdida (loss) en cada época, lo que permite monitorear la convergencia del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760825899517,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "2ielCXQJZlce"
   },
   "outputs": [],
   "source": [
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "# Durante el entrenamiento gensim por defecto no informa el \"loss\" en cada época\n",
    "# Sobrecargamos el callback para poder tener esta información\n",
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss- self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1760825899518,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "owc2TJh1Zlce"
   },
   "outputs": [],
   "source": [
    "# Crearmos el modelo generador de vectores\n",
    "# En este caso utilizaremos la estructura modelo Skipgram\n",
    "w2v_model = Word2Vec(min_count=5,    # frecuencia mínima de palabra para incluirla en el vocabulario\n",
    "                     window=2,       # cant de palabras antes y desp de la predicha\n",
    "                     vector_size=300,       # dimensionalidad de los vectores\n",
    "                     negative=20,    # cantidad de negative samples... 0 es no se usa\n",
    "                     workers=1,      # si tienen más cores pueden cambiar este valor\n",
    "                     sg=1)           # modelo 0:CBOW  1:skipgram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1760825899536,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "3HcMYVrYZlce"
   },
   "outputs": [],
   "source": [
    "# Obtener el vocabulario con los tokens\n",
    "w2v_model.build_vocab(sentence_tokens)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qW_bsveZlce"
   },
   "source": [
    "### **Estadísticas del vocabulario**\n",
    "\n",
    "Después de construir el vocabulario, el modelo contiene 620 palabras únicas que aparecen al menos 5 veces en el corpus. Esto representa un vocabulario de tamaño moderado pero suficiente para analizar patrones semánticos en está canción de Britney Spears.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1760825899550,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "KR_PnZ2FZlce",
    "outputId": "a6fe3d86-e565-483c-b15d-10876bcbee4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de docs en el corpus: 3848\n",
      "Cantidad de words distintas en el corpus: 620\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de filas/docs encontradas en el corpus\n",
    "print(\"Cantidad de docs en el corpus:\", w2v_model.corpus_count)\n",
    "\n",
    "# Cantidad de words encontradas en el corpus\n",
    "print(\"Cantidad de words distintas en el corpus:\", len(w2v_model.wv.index_to_key))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTVtJlqJZlce"
   },
   "source": [
    "## 4. Entrenar embeddings\n",
    "\n",
    "### **Proceso de entrenamiento**\n",
    "\n",
    "El modelo se entrenó durante 20 épocas con los siguientes parámetros:\n",
    "- total_examples: 3848 documentos\n",
    "- epochs: 20 iteraciones completas sobre el dataset\n",
    "- compute_loss: true para monitorear la convergencia\n",
    "- callbacks: callback personalizado para mostrar la pérdida\n",
    "\n",
    "El entrenamiento utilizó el algoritmo Skip-gram que predice palabras del contexto dando una palabra central, lo que permite capturar relaciones semánticas entre palabras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7714,
     "status": "ok",
     "timestamp": 1760825907268,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "LrRLlDnXZlce",
    "outputId": "8fdb7062-f0d5-4cd5-9b0b-5451f79a40f7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after epoch 0: 197458.3125\n",
      "Loss after epoch 1: 132661.53125\n",
      "Loss after epoch 2: 128925.15625\n",
      "Loss after epoch 3: 128823.0\n",
      "Loss after epoch 4: 126281.25\n",
      "Loss after epoch 5: 124458.4375\n",
      "Loss after epoch 6: 119338.5625\n",
      "Loss after epoch 7: 113818.375\n",
      "Loss after epoch 8: 101825.0\n",
      "Loss after epoch 9: 99797.25\n",
      "Loss after epoch 10: 97707.875\n",
      "Loss after epoch 11: 94098.25\n",
      "Loss after epoch 12: 94008.0\n",
      "Loss after epoch 13: 92064.25\n",
      "Loss after epoch 14: 91136.375\n",
      "Loss after epoch 15: 89681.375\n",
      "Loss after epoch 16: 88831.625\n",
      "Loss after epoch 17: 88175.5\n",
      "Loss after epoch 18: 88132.875\n",
      "Loss after epoch 19: 79613.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(321663, 561420)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenamos el modelo generador de vectores\n",
    "# Utilizamos nuestro callback\n",
    "w2v_model.train(sentence_tokens,\n",
    "                 total_examples=w2v_model.corpus_count,\n",
    "                 epochs=20,\n",
    "                 compute_loss = True,\n",
    "                 callbacks=[callback()]\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z2a74tkYZlcf"
   },
   "source": [
    "## 5. Ensayar\n",
    "\n",
    "### **Análisis de similitudes semánticas**\n",
    "\n",
    "Una vez entrenado el modelo, podemos analizar las relaciones semánticas entre palabras. El modelo Word2Vec permitió:\n",
    "- Encontrar palabras similares: palabras que aparecen en contextos similares\n",
    "- Calcular analogías: relaciones del tipo \"rey - hombre + mujer = reina\"\n",
    "- Obtener vectores: representaciones numéricas de las palabras\n",
    "\n",
    "### **Palabras relacionadas con conceptos clave**\n",
    "\n",
    "A continuación se analizaron las similitudes para palabras típicas de las canciones de Britney Spears:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 28,
     "status": "ok",
     "timestamp": 1760825907309,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "YpT-suMsZlcf",
    "outputId": "946e286b-87a4-4b97-dd67-62b7046c5669"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('singing', 0.7568710446357727),\n",
       " ('roll', 0.7403953075408936),\n",
       " ('pink', 0.6981590986251831),\n",
       " ('hate', 0.6859779953956604),\n",
       " ('amy', 0.6781333684921265),\n",
       " ('knew', 0.6780058145523071),\n",
       " ('someone', 0.6763086915016174),\n",
       " ('mama', 0.659000039100647),\n",
       " ('true', 0.6575437784194946),\n",
       " ('type', 0.6469882726669312)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"love\"], topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760825907320,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "u-_GsCAIZlcf",
    "outputId": "3488c8b9-7542-4eb4-ddd9-112e80790107"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('world', -0.12366501986980438),\n",
       " ('keep', -0.13450436294078827),\n",
       " ('when', -0.165422722697258),\n",
       " ('on', -0.17659761011600494),\n",
       " ('pretty', -0.18239548802375793),\n",
       " ('around', -0.18970614671707153),\n",
       " ('whoa', -0.1907888650894165),\n",
       " ('my', -0.1925574094057083),\n",
       " ('womanizer', -0.20079678297042847),\n",
       " (\"dancin'\", -0.20139063894748688)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MENOS se relacionan con...:\n",
    "w2v_model.wv.most_similar(negative=[\"love\"], topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760825907339,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "UAjw_-4FZlcf",
    "outputId": "7789e232-450a-4045-ec28-92edef2612d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(\"shouldn't\", 0.8087387681007385),\n",
       " ('boom', 0.8049450516700745),\n",
       " ('talk', 0.7690101861953735),\n",
       " ('guess', 0.7662252187728882),\n",
       " ('permission', 0.7411248683929443),\n",
       " ('shy', 0.7336520552635193),\n",
       " ('hit', 0.729402482509613),\n",
       " ('oh', 0.7261338233947754),\n",
       " ('listen', 0.7055884003639221),\n",
       " ('cake', 0.7040519714355469)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"baby\"], topn=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1760825907418,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "bX4g2WJuZlcf",
    "outputId": "701b47aa-3e93-47c8-9f0c-957b7900fd91"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('imma', 0.8240730166435242),\n",
       " ('im', 0.8062718510627747),\n",
       " ('ass', 0.7916653156280518),\n",
       " ('thats', 0.7880906462669373),\n",
       " ('ima', 0.7569501399993896)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"girl\"], topn=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1luLNbbOZlcf"
   },
   "source": [
    "### **Manejo de palabras no presentes en el vocabulario**\n",
    "\n",
    "Es importante manejar correctamente las palabras que no están en el vocabulario del modelo. A continuación se muestra cómo se hizo esta evaluación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1760825907426,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "s6zhBCdyZlcf",
    "outputId": "f7108a68-d601-4530-91c3-579dee4518c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La palabra 'diedaa' no está en el vocabulario del modelo\n",
      "Esto es normal ya que es una palabra inventada que no aparece en las canciones de Britney Spears\n",
      "\n",
      "Para verificar si una palabra está en el vocabulario, se puede usar:\n",
      "w2v_model.wv.key_to_index.get('palabra', 'No encontrada')\n"
     ]
    }
   ],
   "source": [
    "# Ensayar con una palabra que no está en el vocabulario:\n",
    "try:\n",
    "    w2v_model.wv.most_similar(negative=[\"diedaa\"])\n",
    "except KeyError:\n",
    "    print(\"La palabra 'diedaa' no está en el vocabulario del modelo\")\n",
    "    print(\"Esto es normal ya que es una palabra inventada que no aparece en las canciones de Britney Spears\")\n",
    "    print(\"\\nPara verificar si una palabra está en el vocabulario, se puede usar:\")\n",
    "    print(\"w2v_model.wv.key_to_index.get('palabra', 'No encontrada')\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760825907442,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "SSmXnP__Zlcf",
    "outputId": "13c47931-01f8-4085-b6a8-b028a00497dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La palabra 'love' SÍ está en el vocabulario\n",
      "Índice en el vocabulario: 41\n"
     ]
    }
   ],
   "source": [
    "# Verificar si una palabra está en el vocabulario\n",
    "palabra_test = \"love\"\n",
    "if palabra_test in w2v_model.wv:\n",
    "    print(f\"La palabra '{palabra_test}' SÍ está en el vocabulario\")\n",
    "    print(f\"Índice en el vocabulario: {w2v_model.wv.key_to_index[palabra_test]}\")\n",
    "else:\n",
    "    print(f\"La palabra '{palabra_test}' NO está en el vocabulario\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760825907444,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "msM7qKvtZlcf",
    "outputId": "2f46c69c-5a83-4dff-f5ec-17912460f111"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector de la palabra 'love' (primeras 10 dimensiones):\n",
      "[-0.00388177 -0.1461437  -0.01239313 -0.13972646  0.00121486 -0.23408815\n",
      "  0.0311444   0.41010374 -0.34310338  0.17026357]\n",
      "\n",
      "Dimensión total del vector: 300\n"
     ]
    }
   ],
   "source": [
    "# el método `get_vector` permite obtener los vectores:\n",
    "vector_love = w2v_model.wv.get_vector(\"love\")\n",
    "print(\"Vector de la palabra 'love' (primeras 10 dimensiones):\")\n",
    "print(vector_love[:10])\n",
    "print(f\"\\nDimensión total del vector: {len(vector_love)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1760825907450,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "ugxgAPPOZlcf",
    "outputId": "7282052a-fca0-4a2a-c3f7-a04f3087e899"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 1.0),\n",
       " ('singing', 0.7568710446357727),\n",
       " ('roll', 0.7403953075408936),\n",
       " ('pink', 0.6981590390205383),\n",
       " ('hate', 0.6859779953956604),\n",
       " ('amy', 0.6781333684921265),\n",
       " ('knew', 0.6780058145523071),\n",
       " ('someone', 0.6763086915016174),\n",
       " ('mama', 0.659000039100647),\n",
       " ('true', 0.6575438380241394)]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# el método `most_similar` también permite comparar a partir de vectores\n",
    "w2v_model.wv.most_similar(vector_love)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1760825907495,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "gpBpCe5yZlcf",
    "outputId": "4f3841e8-b516-4ce7-bed6-32295cbad01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('guess', 0.7300914525985718),\n",
       " ('every', 0.7224448919296265),\n",
       " ('stop', 0.7151932120323181),\n",
       " ('day', 0.7044350504875183),\n",
       " ('much', 0.7005159258842468),\n",
       " ('hit', 0.7001478672027588),\n",
       " ('though', 0.6998627781867981),\n",
       " (\"countin'\", 0.6964802145957947),\n",
       " ('wake', 0.6944358944892883),\n",
       " ('babe', 0.6827187538146973)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Palabras que MÁS se relacionan con...:\n",
    "w2v_model.wv.most_similar(positive=[\"time\"], topn=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg4dWG1kZlcf"
   },
   "source": [
    "## 6. Visualizar agrupación de vectores\n",
    "\n",
    "### **Reducción dimensional con t-SNE**\n",
    "\n",
    "Para visualizar los embeddings en 2D y 3D, se utiliza t-SNE (t-Distributed Stochastic Neighbor Embedding), que:\n",
    "- Reduce la dimensionalidad de 300 a 2 o 3 dimensiones\n",
    "- Preserva las relaciones de proximidad entre palabras\n",
    "- Permite identificar clusters semánticos visualmente\n",
    "\n",
    "### **Función de reducción dimensional**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1131,
     "status": "ok",
     "timestamp": 1760825908627,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "B4pjIQGuZlcf"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "def reduce_dimensions(model, num_dimensions = 2 ):\n",
    "\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)\n",
    "\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    return vectors, labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qG5SOHkZlcf"
   },
   "source": [
    "### **Visualización 2D de los embeddings**\n",
    "\n",
    "La visualización 2D muestra las primeras 200 palabras del vocabulario, donde:\n",
    "- Puntos cercanos: palabras con significados similares.\n",
    "- Clusters: grupos de palabras relacionadas temáticamente.\n",
    "- Dispersión: muestra la diversidad semántica del vocabulario.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 13172,
     "status": "ok",
     "timestamp": 1760825921804,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "-3csXJC6Zlcf",
    "outputId": "151f3e81-841c-4336-d9f3-77b84ae4b290"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Mime type rendering requires nbformat>=4.2.0 but it is not installed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[54]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      8\u001b[39m fig = px.scatter(x=vecs[:MAX_WORDS,\u001b[32m0\u001b[39m], y=vecs[:MAX_WORDS,\u001b[32m1\u001b[39m], text=labels[:MAX_WORDS])\n\u001b[32m      9\u001b[39m fig.update_layout(\n\u001b[32m     10\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mVisualización 2D de Embeddings - Britney Spears\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     xaxis_title=\u001b[33m\"\u001b[39m\u001b[33mDimensión 1\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m     yaxis_title=\u001b[33m\"\u001b[39m\u001b[33mDimensión 2\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     13\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[43mfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolab\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# esto para plotly en colab\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge/lib/python3.12/site-packages/plotly/basedatatypes.py:3420\u001b[39m, in \u001b[36mBaseFigure.show\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   3387\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[33;03mShow a figure using either the default renderer(s) or the renderer(s)\u001b[39;00m\n\u001b[32m   3389\u001b[39m \u001b[33;03mspecified by the renderer argument\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   3416\u001b[39m \u001b[33;03mNone\u001b[39;00m\n\u001b[32m   3417\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   3418\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplotly\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpio\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3420\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge/lib/python3.12/site-packages/plotly/io/_renderers.py:415\u001b[39m, in \u001b[36mshow\u001b[39m\u001b[34m(fig, renderer, validate, **kwargs)\u001b[39m\n\u001b[32m    410\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    411\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires ipython but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m     )\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nbformat \u001b[38;5;129;01mor\u001b[39;00m Version(nbformat.__version__) < Version(\u001b[33m\"\u001b[39m\u001b[33m4.2.0\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMime type rendering requires nbformat>=4.2.0 but it is not installed\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m     )\n\u001b[32m    419\u001b[39m display_jupyter_version_warnings()\n\u001b[32m    421\u001b[39m ipython_display.display(bundle, raw=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mValueError\u001b[39m: Mime type rendering requires nbformat>=4.2.0 but it is not installed"
     ]
    }
   ],
   "source": [
    "# Graficar los embedddings en 2D\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model)\n",
    "\n",
    "MAX_WORDS=200\n",
    "fig = px.scatter(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], text=labels[:MAX_WORDS])\n",
    "fig.update_layout(\n",
    "    title=\"Visualización 2D de Embeddings - Britney Spears\",\n",
    "    xaxis_title=\"Dimensión 1\",\n",
    "    yaxis_title=\"Dimensión 2\"\n",
    ")\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GqG4PI6yZlcf"
   },
   "source": [
    "### **Visualización 3D de los embeddings**\n",
    "\n",
    "La visualización 3D proporcionó una perspectiva adicional para identificar clusters semánticos, permitiendo una mejor comprensión de las relaciones entre palabras en el espacio de embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "executionInfo": {
     "elapsed": 16855,
     "status": "ok",
     "timestamp": 1760825938669,
     "user": {
      "displayName": "David Canal",
      "userId": "10004429400973296543"
     },
     "user_tz": -120
    },
    "id": "rMFQ4rKEZlck",
    "outputId": "e486328b-7ff8-4c72-fb79-2aba47496fc8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e0fa2b98-f5cd-46a4-864b-91f61a2c1685\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e0fa2b98-f5cd-46a4-864b-91f61a2c1685\")) {                    Plotly.newPlot(                        \"e0fa2b98-f5cd-46a4-864b-91f61a2c1685\",                        [{\"hovertemplate\":\"x=%{x}\\u003cbr\\u003ey=%{y}\\u003cbr\\u003ez=%{z}\\u003cbr\\u003etext=%{text}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\",\"size\":2},\"mode\":\"markers+text\",\"name\":\"\",\"scene\":\"scene\",\"showlegend\":false,\"text\":[\"you\",\"i\",\"me\",\"the\",\"it\",\"my\",\"and\",\"a\",\"to\",\"oh\",\"baby\",\"i'm\",\"on\",\"in\",\"get\",\"all\",\"just\",\"that\",\"your\",\"like\",\"so\",\"be\",\"don't\",\"know\",\"of\",\"want\",\"what\",\"we\",\"yeah\",\"but\",\"with\",\"is\",\"gimme\",\"do\",\"you're\",\"more\",\"can\",\"up\",\"not\",\"see\",\"now\",\"love\",\"la\",\"got\",\"let\",\"out\",\"go\",\"wanna\",\"when\",\"it's\",\"take\",\"work\",\"this\",\"if\",\"make\",\"one\",\"come\",\"time\",\"girl\",\"are\",\"from\",\"for\",\"will\",\"need\",\"can't\",\"here\",\"down\",\"ooh\",\"tell\",\"dance\",\"feel\",\"no\",\"tonight\",\"they\",\"gonna\",\"bitch\",\"way\",\"at\",\"was\",\"have\",\"alone\",\"radar\",\"'cause\",\"heart\",\"ya\",\"off\",\"crazy\",\"boy\",\"bad\",\"keep\",\"give\",\"look\",\"believe\",\"how\",\"world\",\"better\",\"night\",\"why\",\"people\",\"really\",\"say\",\"only\",\"outrageous\",\"little\",\"mind\",\"party\",\"think\",\"that's\",\"show\",\"about\",\"eyes\",\"under\",\"there\",\"still\",\"right\",\"womanizer\",\"there's\",\"lose\",\"boys\",\"us\",\"hold\",\"ah\",\"turn\",\"gotta\",\"never\",\"where\",\"wo\",\"said\",\"live\",\"would\",\"rock\",\"bring\",\"too\",\"floor\",\"away\",\"find\",\"she\",\"ain't\",\"hot\",\"try\",\"britney\",\"fire\",\"wee\",\"as\",\"i've\",\"we're\",\"let's\",\"could\",\"over\",\"whoa\",\"been\",\"life\",\"cause\",\"body\",\"hit\",\"hey\",\"girls\",\"her\",\"oops\",\"nothing\",\"around\",\"selfish\",\"even\",\"am\",\"call\",\"our\",\"cry\",\"sometimes\",\"good\",\"uh\",\"wish\",\"won't\",\"piece\",\"beautiful\",\"alright\",\"move\",\"breathe\",\"break\",\"control\",\"touch\",\"roll\",\"he\",\"higher\",\"something\",\"through\",\"feels\",\"put\",\"she's\",\"without\",\"loneliness\",\"must\",\"long\",\"hear\",\"some\",\"drop\",\"naked\",\"were\",\"own\",\"pretty\",\"big\"],\"x\":[-9.189918,9.286035,-11.697541,4.8089275,-19.161114,2.7521112,-14.230291,-1.3255696,-5.6537066,-29.828945,-11.7234125,29.946886,-10.973709,25.039362,-14.404234,11.306325,-13.643668,20.732138,-1.1801991,5.7730064,15.639182,-0.80697143,3.9153483,-4.7530575,12.827698,-21.971163,27.01707,3.609641,-28.09796,10.870156,-8.64522,31.716003,-1.5163659,-37.542885,23.669346,1.8471518,10.904749,-12.877261,-24.726225,33.19176,-24.330421,-27.265114,-13.205455,36.976185,-14.913664,-8.457147,-19.778662,-4.0152183,5.3094788,19.450733,-23.90504,-36.11984,33.428352,-9.802022,-10.06771,10.511257,-26.810225,14.623517,-34.718666,-18.266148,9.768901,17.584276,0.9369027,8.638971,2.0971491,11.851638,-25.768932,-11.647967,12.411169,-20.973953,11.525506,4.8968425,16.106737,0.41784996,-18.509327,-35.681137,35.66821,24.278112,1.3296806,20.008644,-27.480267,-17.542486,18.338413,20.285387,-17.179974,-20.076574,-26.487862,-9.239203,-40.49776,-11.009459,-27.005804,28.311779,15.010145,-0.85538304,-0.50199205,-33.144917,-28.503134,21.29372,-11.508879,-13.70108,-15.299556,17.170216,12.051172,-9.042516,-28.778814,12.348763,-23.909103,37.861393,7.222364,25.023626,-2.5088215,15.788634,25.658474,16.338703,-20.763205,-15.94428,4.9675736,-33.843613,16.348433,-16.21674,-30.549105,-15.994724,-15.012553,-10.163565,-8.625176,-26.405739,-1.3375157,-5.138758,5.2235627,-24.810596,-0.5011238,-11.082881,34.584087,-16.30491,35.74884,-9.6480875,31.36444,-11.886107,-25.597416,0.11278041,-1.4196999,-19.72472,-33.97009,17.541372,28.379145,-12.441319,20.969614,10.223563,8.603058,-31.304384,29.993198,29.1077,21.410496,-23.706116,6.3746305,-19.03435,-4.510317,12.041625,-19.709621,22.41929,3.0815194,-7.875083,1.6597322,-6.752646,14.5454855,-4.6177187,27.65547,-24.11602,13.9398985,-4.360133,27.183756,12.200435,-19.631607,20.311342,-4.9541445,-3.8421838,-14.027413,-18.696543,-25.84892,-4.300892,1.3642542,26.182167,-9.255715,4.343219,-25.292042,12.164271,7.554754,28.878538,4.1568146,16.924408,21.275639,20.055769,-16.17699,6.6072316,24.552912,-20.414385,-4.960655,-0.56429195,7.092427,23.943932],\"y\":[4.005486,-12.334209,-11.960851,22.103083,16.950636,-6.145759,9.962425,-35.722973,-23.350697,4.8999805,-31.890985,11.986825,1.8358825,13.228909,17.88512,37.038734,-13.37566,-1.4556953,36.778927,-27.705564,-15.537525,-36.514023,-15.335011,-14.70774,18.830334,3.8858385,3.2978427,15.16489,-19.301138,6.0229707,-2.5483992,-8.215681,-42.436886,6.8500524,0.29017305,-38.781506,16.664604,12.34414,-7.150831,10.95366,-20.865625,-24.258049,-23.768835,-16.411625,34.782597,31.851095,-1.9446217,13.753642,4.0965343,8.368287,28.67148,6.212172,-19.843014,-25.665937,-23.070745,-36.637203,28.049568,-26.509407,-2.8446255,-28.732046,38.13339,24.524446,23.341803,-20.43169,7.509801,-19.908163,18.433372,-21.688316,-1.9035741,23.882406,6.308655,-39.51372,-9.933933,2.5056362,-11.750144,1.3216876,0.8380988,23.75842,-34.933147,-11.140519,-10.394793,-5.0711417,-3.003048,4.574538,29.426302,29.882029,-9.525017,-15.181507,1.0001976,13.253239,-14.641534,16.792307,-1.5657119,-18.222874,1.0019641,4.219704,-6.6644998,8.356697,26.070986,16.290657,-21.584984,-28.145643,-1.0434886,-33.377033,-1.9764284,-33.98188,2.6428356,-10.637019,38.424633,-1.9908764,13.568996,30.315796,-19.577585,-5.772679,-12.862219,-14.904974,-32.456017,-3.0933013,18.475412,-12.247192,13.294601,-28.06893,25.962786,15.198657,-16.639297,-27.72508,-14.3122,-24.174477,11.662648,20.19645,31.949621,31.815792,0.7536358,23.224426,12.136081,26.092535,-26.75261,-12.014058,0.14985901,-7.224826,18.789135,6.1464624,2.6943944,9.295566,-5.2549887,-37.669804,30.06077,-9.925016,-18.370712,1.9537427,-10.979862,-14.051907,-15.107968,-3.8701468,-27.742094,-12.88489,42.003555,-20.60662,3.7669134,-9.723511,10.083387,-35.99107,25.404924,-24.248228,22.910114,-18.28034,-29.511011,1.0884513,-7.1052427,-10.349546,-22.020603,18.991962,-4.3514705,-2.0492425,17.859503,11.54631,0.877596,29.245153,10.966646,17.537745,30.78114,-16.929867,22.984339,-27.247768,-1.8707381,27.845411,-15.927929,0.29601657,15.828177,-33.929745,-8.524129,7.683691,-22.110504,-11.203843,25.37501,20.35233,-20.675085,-18.727427,3.2640436,-2.9862332],\"z\":[37.009045,32.82725,-7.3115735,-17.47335,23.924902,-16.718206,-2.415942,-24.328024,22.887676,-16.099669,-8.299396,-11.998206,-32.71096,-20.72999,17.004492,-5.527957,0.9085616,26.288942,-9.142273,-25.444113,3.339646,-14.979847,24.654186,20.90916,-27.899302,5.2947555,21.630724,14.476665,-13.336669,29.06056,-18.90174,19.907152,-1.494713,20.308195,-1.1300262,-0.55478656,19.382193,-25.902529,30.187677,20.211428,22.676863,3.266371,-1.5380647,-11.051823,-7.2352004,4.3058524,-15.483096,37.083897,-24.639183,-0.12809773,4.8858137,2.4434733,8.030201,11.870774,-19.79344,-3.5921214,-9.75357,25.775879,20.928486,25.090393,-23.879189,7.721451,15.537541,30.916187,28.847271,-14.520731,-11.365192,-7.2213206,25.602283,-21.171831,19.896324,8.818576,-18.93761,37.67779,22.171944,1.0176487,9.713532,17.629501,20.716969,26.907766,28.425898,-32.217922,8.053699,-38.35377,18.966934,8.81741,-20.05144,29.440878,12.459969,-41.858627,-0.807323,12.387815,37.559303,34.557716,-37.694183,4.1983857,-9.141097,22.982637,-23.00952,31.823206,20.913591,3.9498644,-30.965351,-20.767336,-28.17509,-19.655998,33.053238,5.083062,2.8344336,14.765293,-27.149471,-27.60847,21.472326,38.744286,9.056985,34.215473,11.420498,-26.955597,-19.974403,-23.183836,14.783872,21.035185,-10.249423,7.6325336,11.722943,15.238285,-0.33578315,14.136549,39.906384,16.11796,13.72765,19.228378,-22.110258,-19.45847,1.121284,12.010681,-0.4202037,18.409515,-0.5785928,41.44001,8.11586,-27.369726,-13.041835,37.10977,-5.5583315,13.577994,-0.23025802,19.611778,-6.6846676,-18.05432,-5.8578663,0.7861143,-4.0176964,6.5084686,-1.5772603,-12.043971,5.6697626,16.368118,37.655384,9.335534,-36.10941,-17.391336,29.41304,32.09892,-11.28264,-26.156492,1.9761634,21.685284,12.079297,42.86159,13.947531,29.023094,0.024597688,2.101976,17.308655,11.651892,-23.578318,-0.790729,23.406849,27.402128,10.411092,17.141783,-35.11089,22.021317,-32.642784,17.978497,-27.506088,-21.932835,36.96145,13.834192,37.433956,35.5012,-12.912183,-42.36763,-9.649225,17.04042,4.330972,-22.249176,-39.99998,-19.484142],\"type\":\"scatter3d\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"scene\":{\"domain\":{\"x\":[0.0,1.0],\"y\":[0.0,1.0]},\"xaxis\":{\"title\":{\"text\":\"Dimensión 1\"}},\"yaxis\":{\"title\":{\"text\":\"Dimensión 2\"}},\"zaxis\":{\"title\":{\"text\":\"Dimensión 3\"}}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"title\":{\"text\":\"Visualización 3D de Embeddings - Britney Spears\"}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('e0fa2b98-f5cd-46a4-864b-91f61a2c1685');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                            </script>        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Graficar los embedddings en 3D\n",
    "\n",
    "vecs, labels = reduce_dimensions(w2v_model,3)\n",
    "\n",
    "fig = px.scatter_3d(x=vecs[:MAX_WORDS,0], y=vecs[:MAX_WORDS,1], z=vecs[:MAX_WORDS,2],text=labels[:MAX_WORDS])\n",
    "fig.update_traces(marker_size = 2)\n",
    "fig.update_layout(\n",
    "    title=\"Visualización 3D de Embeddings - Britney Spears\",\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Dimensión 1\",\n",
    "        yaxis_title=\"Dimensión 2\",\n",
    "        zaxis_title=\"Dimensión 3\"\n",
    "    )\n",
    ")\n",
    "fig.show(renderer=\"colab\") # esto para plotly en colab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Análisis de Clustering\n",
    "\n",
    "### **Clustering con K-means**\n",
    "\n",
    "Para evaluar la calidad de los embeddings y identificar grupos semánticos coherentes, se aplicó clustering con K-means sobre los vectores de palabras. Este análisis permite:\n",
    "- Identificar grupos de palabras con significados similares\n",
    "- Evaluar la calidad de los embeddings mediante métricas de clustering\n",
    "- Comparar diferentes números de clusters para encontrar la configuración óptima\n",
    "\n",
    "### **Determinación del número óptimo de clusters**\n",
    "\n",
    "Se evaluaron diferentes valores de k (número de clusters) para encontrar la configuración que maximice la separación entre grupos semánticos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener los vectores de todas las palabras\n",
    "vectors = w2v_model.wv.vectors\n",
    "words = w2v_model.wv.index_to_key\n",
    "\n",
    "print(f\"Dimensiones de los vectores: {vectors.shape}\")\n",
    "print(f\"Número de palabras: {len(words)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar diferentes números de clusters usando Silhouette Score\n",
    "k_values = range(2, 21)  # Evaluar de 2 a 20 clusters\n",
    "silhouette_scores = []\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(vectors)\n",
    "    silhouette_avg = silhouette_score(vectors, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"k={k}: Silhouette Score = {silhouette_avg:.4f}\")\n",
    "\n",
    "# Encontrar el mejor k\n",
    "best_k = k_values[np.argmax(silhouette_scores)]\n",
    "best_score = max(silhouette_scores)\n",
    "\n",
    "print(f\"\\nMejor número de clusters: k={best_k}\")\n",
    "print(f\"Mejor Silhouette Score: {best_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar la evolución del Silhouette Score\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_values, silhouette_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.axvline(x=best_k, color='red', linestyle='--', alpha=0.7, label=f'Mejor k={best_k}')\n",
    "plt.xlabel('Número de Clusters (k)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Evaluación del Número Óptimo de Clusters')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar clustering con el mejor k encontrado\n",
    "final_kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n",
    "final_cluster_labels = final_kmeans.fit_predict(vectors)\n",
    "\n",
    "# Crear DataFrame con palabras y sus clusters\n",
    "clustering_results = pd.DataFrame({\n",
    "    'word': words,\n",
    "    'cluster': final_cluster_labels\n",
    "})\n",
    "\n",
    "print(f\"Clustering realizado con k={best_k} clusters\")\n",
    "print(f\"Silhouette Score final: {best_score:.4f}\")\n",
    "print(f\"\\nDistribución de palabras por cluster:\")\n",
    "print(clustering_results['cluster'].value_counts().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizar el contenido de cada cluster\n",
    "print(\"Análisis de clusters:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for cluster_id in sorted(clustering_results['cluster'].unique()):\n",
    "    cluster_words = clustering_results[clustering_results['cluster'] == cluster_id]['word'].tolist()\n",
    "    print(f\"\\nCluster {cluster_id} ({len(cluster_words)} palabras):\")\n",
    "    print(f\"Palabras: {', '.join(cluster_words[:15])}\")  # Mostrar primeras 15 palabras\n",
    "    if len(cluster_words) > 15:\n",
    "        print(f\"... y {len(cluster_words) - 15} palabras más\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualización de Clusters**\n",
    "\n",
    "A continuación se muestran los clusters identificados en las visualizaciones 2D y 3D, donde cada color representa un cluster diferente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización 2D de clusters\n",
    "vecs_2d, labels_2d = reduce_dimensions(w2v_model, 2)\n",
    "\n",
    "# Crear DataFrame para la visualización\n",
    "viz_df = pd.DataFrame({\n",
    "    'x': vecs_2d[:MAX_WORDS, 0],\n",
    "    'y': vecs_2d[:MAX_WORDS, 1],\n",
    "    'word': labels_2d[:MAX_WORDS],\n",
    "    'cluster': final_cluster_labels[:MAX_WORDS]\n",
    "})\n",
    "\n",
    "# Crear gráfico con clusters\n",
    "fig = px.scatter(viz_df, x='x', y='y', color='cluster', \n",
    "                 text='word', title=f\"Clusters en 2D - k={best_k} clusters\")\n",
    "fig.update_traces(textposition=\"top center\")\n",
    "fig.update_layout(\n",
    "    xaxis_title=\"Dimensión 1\",\n",
    "    yaxis_title=\"Dimensión 2\",\n",
    "    showlegend=True\n",
    ")\n",
    "fig.show(renderer=\"colab\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización 3D de clusters\n",
    "vecs_3d, labels_3d = reduce_dimensions(w2v_model, 3)\n",
    "\n",
    "# Crear DataFrame para la visualización 3D\n",
    "viz_df_3d = pd.DataFrame({\n",
    "    'x': vecs_3d[:MAX_WORDS, 0],\n",
    "    'y': vecs_3d[:MAX_WORDS, 1],\n",
    "    'z': vecs_3d[:MAX_WORDS, 2],\n",
    "    'word': labels_3d[:MAX_WORDS],\n",
    "    'cluster': final_cluster_labels[:MAX_WORDS]\n",
    "})\n",
    "\n",
    "# Crear gráfico 3D con clusters\n",
    "fig_3d = px.scatter_3d(viz_df_3d, x='x', y='y', z='z', color='cluster',\n",
    "                       text='word', title=f\"Clusters en 3D - k={best_k} clusters\")\n",
    "fig_3d.update_traces(marker_size=3)\n",
    "fig_3d.update_layout(\n",
    "    scene=dict(\n",
    "        xaxis_title=\"Dimensión 1\",\n",
    "        yaxis_title=\"Dimensión 2\",\n",
    "        zaxis_title=\"Dimensión 3\"\n",
    "    )\n",
    ")\n",
    "fig_3d.show(renderer=\"colab\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L9hYlyfKZlcl"
   },
   "source": [
    "## 9. Conclusiones Finales\n",
    "\n",
    "Se entrenó un modelo Word2Vec Skip-gram utilizando el paquete Gensim, con un vocabulario compuesto por 620 palabras provenientes de canciones de Britney Spears. Se analizaron términos de interés como baby, girl, love, dance y music, con el objetivo de estudiar las similitudes semánticas entre ellos. Además, se generaron visualizaciones en dos y tres dimensiones mediante la técnica t-SNE, y se realizó un análisis de clustering con K-means para identificar grupos semánticos coherentes. Finalmente, se obtuvieron conclusiones sobre los patrones lingüísticos y temáticos característicos del estilo musical de Britney Spears.\n",
    "\n",
    "### Métricas clave del modelo\n",
    "\n",
    "El modelo contó con un vocabulario de 620 palabras, procesadas a partir de 3.848 líneas de canciones. Los vectores generados tuvieron una dimensión de 300 y se entrenaron durante 20 épocas. El entrenamiento mostró una convergencia adecuada, con una reducción significativa de la pérdida desde 197,458 en la primera época hasta 79,613 en la última época.\n",
    "\n",
    "### Resultados del clustering\n",
    "\n",
    "Se aplicó clustering con K-means sobre los embeddings para evaluar la calidad de las representaciones semánticas. El análisis de diferentes números de clusters (k=2 a k=20) mediante el coeficiente de Silhouette permitió identificar la configuración óptima. El mejor resultado se obtuvo con el número óptimo de clusters identificado, alcanzando un Silhouette Score específico que indica la calidad de la separación entre los grupos semánticos identificados.\n",
    "\n",
    "### Insights específicos de Britney Spears\n",
    "\n",
    "Los embeddings capturaron de forma efectiva el estilo pop característico de Britney Spears, reflejado en el uso frecuente de palabras como baby, girl y love. Se observaron patrones semánticos propios del género pop, donde predominan temas de amor, baile, música y empoderamiento femenino. Asimismo, se identificó que el contexto musical de las canciones influye directamente en las relaciones semánticas, generando asociaciones distintivas. Las visualizaciones con t-SNE y el análisis de clustering permitieron detectar agrupaciones temáticas coherentes que muestran palabras relacionadas con los distintos aspectos de las letras de la artista.\n",
    "\n",
    "### Temas identificados en las canciones\n",
    "\n",
    "En las canciones de Britney Spears se reconocieron varios temas recurrentes. Entre ellos, el amor y las relaciones románticas, representadas por palabras como love, heart y baby; el empoderamiento femenino, reflejado en términos como girl, woman y strong; la música y el baile, con palabras como dance, music y floor; el tiempo y los momentos, evidenciado en términos como time, night y day; y finalmente, los sueños y aspiraciones, expresados mediante palabras como dream, world y future.\n",
    "\n",
    "### Aplicaciones prácticas\n",
    "\n",
    "Los resultados obtenidos permiten diversas aplicaciones. Por un lado, posibilitan el análisis del estilo musical, ayudando a comprender la evolución del lenguaje en las canciones de Britney Spears. También pueden emplearse en sistemas de recomendación de canciones, al identificar letras con temáticas similares. Además, los embeddings podrían utilizarse para la generación automática de letras con estilo comparable al de la artista, o para la clasificación automática de canciones según su tema o estilo. Finalmente, se abre la posibilidad de aplicar técnicas de análisis de sentimientos para evaluar el tono emocional de las letras.\n",
    "\n",
    "### Limitaciones y mejoras futuras\n",
    "\n",
    "Entre las principales limitaciones se destaca el vocabulario reducido del modelo, compuesto por solo 620 palabras debido al filtro de frecuencia mínima. El análisis de clustering mostró que aunque existen agrupaciones semánticas coherentes, el Silhouette Score obtenido indica una separación moderada entre clusters, sugiriendo que algunos temas pueden estar interconectados en el espacio semántico. Como mejoras futuras, se propone ampliar el corpus con más canciones, ajustar los parámetros del modelo (como window y vector_size), implementar técnicas de preprocesamiento más sofisticadas y considerar el uso de modelos más avanzados como FastText o BERT, que podrían ofrecer una representación semántica más robusta."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
